{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, RocCurveDisplay\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "train_scaled = pd.read_csv(\"data/train_scaled.csv\")\n",
    "train_removed = pd.read_csv(\"data/train_removed.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Data와 Test Data 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = train_scaled.drop(['Class'], axis=1)\n",
    "y_scaled = train_scaled['Class']\n",
    "X_removed = train_removed.drop(['Class'], axis=1)\n",
    "y_removed = train_removed['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_scaled_train: 399360행, X_scaled_test: 99841행, y_scaled_train: 399360행, y_scaled_test: 99841행\n",
      "X_removed_train: 163503행, X_removed_test: 40876행, y_removed_train: 163503행, y_removed_test: 40876행\n"
     ]
    }
   ],
   "source": [
    "X_scaled_train, X_scaled_test, y_scaled_train, y_scaled_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=0)\n",
    "X_removed_train, X_removed_test, y_removed_train, y_removed_test = train_test_split(X_removed, y_removed, test_size=0.2, random_state=0)\n",
    "print(\"X_scaled_train: {0}행, X_scaled_test: {1}행, y_scaled_train: {2}행, y_scaled_test: {3}행\".\\\n",
    "    format(X_scaled_train.shape[0], X_scaled_test.shape[0], y_scaled_train.shape[0], y_scaled_test.shape[0]))\n",
    "print(\"X_removed_train: {0}행, X_removed_test: {1}행, y_removed_train: {2}행, y_removed_test: {3}행\".\\\n",
    "    format(X_removed_train.shape[0], X_removed_test.shape[0], y_removed_train.shape[0], y_removed_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Train Data의 Genuine Transaction(클래스 0): 398659건\n",
      "Scaled Train Data의 Fraudulent Transaction(클래스 1): 701건\n",
      "Fraudulent / Genuine: 0.001758%\n"
     ]
    }
   ],
   "source": [
    "scaled_train = pd.merge(X_scaled_train, y_scaled_train, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "print(\"Scaled Train Data의 Genuine Transaction(클래스 0): {}건\".format(scaled_train['Class'].value_counts()[0]))\n",
    "print(\"Scaled Train Data의 Fraudulent Transaction(클래스 1): {}건\".format(scaled_train['Class'].value_counts()[1]))\n",
    "print(\"Fraudulent / Genuine: {:4f}%\".format(scaled_train['Class'].value_counts()[1]/scaled_train['Class'].value_counts()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Train Data의 Genuine Transaction(클래스 0): 163426건\n",
      "Removed Train Data의 Fraudulent Transaction(클래스 1): 77건\n",
      "Fraudulent / Genuine: 0.000471%\n"
     ]
    }
   ],
   "source": [
    "removed_train = pd.merge(X_removed_train, y_removed_train, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "print(\"Removed Train Data의 Genuine Transaction(클래스 0): {}건\".format(removed_train['Class'].value_counts()[0]))\n",
    "print(\"Removed Train Data의 Fraudulent Transaction(클래스 1): {}건\".format(removed_train['Class'].value_counts()[1]))\n",
    "print(\"Fraudulent / Genuine: {:4f}%\".format(removed_train['Class'].value_counts()[1]/removed_train['Class'].value_counts()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test = pd.merge(X_scaled_test, y_scaled_test, how='inner', left_index=True, right_index=True)\n",
    "removed_test = pd.merge(X_removed_test, y_removed_test, how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dtype(dataframe):\n",
    "    dataframe_converted = dataframe.copy()\n",
    "    float64_columns = []\n",
    "    int64_columns = []\n",
    "\n",
    "    for column in dataframe_converted.columns:\n",
    "        if dataframe_converted[column].dtype == 'float64':\n",
    "            float64_columns.append(column)\n",
    "        elif dataframe_converted[column].dtype == 'int64':\n",
    "            int64_columns.append(column)\n",
    "    \n",
    "    for column in float64_columns:\n",
    "        dataframe_converted[column] = dataframe_converted[column].astype('float16')\n",
    "    \n",
    "    for column in int64_columns:\n",
    "        dataframe_converted[column] = dataframe_converted[column].astype('int8')\n",
    "\n",
    "    return dataframe_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = convert_dtype(scaled_train)\n",
    "removed = convert_dtype(removed_train)\n",
    "test_scaled = convert_dtype(scaled_test)\n",
    "test_removed = convert_dtype(removed_test) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터: scaled와 removed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "언더샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersampling(data):\n",
    "    class_0 = data[data['Class']==0]\n",
    "    class_1 = data[data['Class']==1]\n",
    "    wanted_ratio = class_1.shape[0] * 10/ class_0.shape[0]\n",
    "    sample_size = int((class_1.shape[0] * (1-wanted_ratio)) / wanted_ratio)\n",
    "    class_0_sampled_df = class_0.sample(n=sample_size, random_state=0)\n",
    "    train_sampled = pd.concat([class_0_sampled_df, class_1], axis=0)\n",
    "    return train_sampled"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터와 모델 선택   \n",
    "DecisionTree, LogisticRegression, KNeighborsClassifier, RandomForestClassifier, XGBClassifier, LGBMClassifier, CatboostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(datas, classifiers):\n",
    "    result = []\n",
    "    for data_name, data in datas.items():\n",
    "        X = data.drop(['Class'], axis=1)\n",
    "        y = data['Class']\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "        sampled_train = undersampling(pd.concat([X_train, y_train], axis=1))\n",
    "        sampled_X_train = sampled_train.drop(['Class'], axis=1)\n",
    "        sampled_y_train = sampled_train['Class']\n",
    "        for classifier in classifiers:\n",
    "            classifier.fit(sampled_X_train, sampled_y_train)\n",
    "            y_pred_proba = classifier.predict_proba(X_val)[:, 1]                    \n",
    "            score = roc_auc_score(y_val, y_pred_proba)\n",
    "            result.append([data_name, classifier.__class__.__name__, score])\n",
    "    df = pd.DataFrame(result, columns=['data', 'model', 'roc_auc']).sort_values('roc_auc', ascending=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier()\n",
    "lr_clf = LogisticRegression()\n",
    "knn_clf = KNeighborsClassifier()\n",
    "rf_clf = RandomForestClassifier()\n",
    "xgb_clf = XGBClassifier()\n",
    "lgbm_clf = LGBMClassifier()\n",
    "cat_clf = CatBoostClassifier(verbose=False)\n",
    "\n",
    "classifiers = [dt_clf, lr_clf, knn_clf, rf_clf, xgb_clf, lgbm_clf, cat_clf]\n",
    "datas = {\"outlier_scaled\": scaled,  \"outlier_removed\": removed}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>model</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>outlier_scaled</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.889629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>outlier_scaled</td>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.888952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>outlier_scaled</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.880137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outlier_scaled</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.879137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outlier_scaled</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.870068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outlier_scaled</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.742622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>outlier_scaled</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.717009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>outlier_removed</td>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.664308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>outlier_removed</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.621654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>outlier_removed</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.615642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>outlier_removed</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.582604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>outlier_removed</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.571195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>outlier_removed</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.496741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>outlier_removed</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.491524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               data                   model   roc_auc\n",
       "5    outlier_scaled          LGBMClassifier  0.889629\n",
       "6    outlier_scaled      CatBoostClassifier  0.888952\n",
       "3    outlier_scaled  RandomForestClassifier  0.880137\n",
       "4    outlier_scaled           XGBClassifier  0.879137\n",
       "1    outlier_scaled      LogisticRegression  0.870068\n",
       "2    outlier_scaled    KNeighborsClassifier  0.742622\n",
       "0    outlier_scaled  DecisionTreeClassifier  0.717009\n",
       "13  outlier_removed      CatBoostClassifier  0.664308\n",
       "8   outlier_removed      LogisticRegression  0.621654\n",
       "11  outlier_removed           XGBClassifier  0.615642\n",
       "10  outlier_removed  RandomForestClassifier  0.582604\n",
       "12  outlier_removed          LGBMClassifier  0.571195\n",
       "7   outlier_removed  DecisionTreeClassifier  0.496741\n",
       "9   outlier_removed    KNeighborsClassifier  0.491524"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification(datas, classifiers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터: outlier_scaled 선택   \n",
    "모델: CatBoostClassifier와 XGBoostClassifier, LGBMClassifier 3개 모델 선택"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_parameter_search(data, classifier, classifiers_parameters, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "    result = pd.DataFrame()\n",
    "\n",
    "    X = data.drop(['Class'], axis=1)\n",
    "    y = data['Class']\n",
    "\n",
    "    for clf, params in classifiers_parameters.items():\n",
    "        model = classifier[clf]\n",
    "        param_grid = ParameterGrid(params)\n",
    "\n",
    "        for param in param_grid:\n",
    "            scores = []\n",
    "\n",
    "            for train_index, val_index in skf.split(X, y):\n",
    "                X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "                y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "                # Undersampling\n",
    "                sampled_train = undersampling(pd.concat([X_train, y_train], axis=1))\n",
    "                sampled_X_train = sampled_train.drop(['Class'], axis=1)\n",
    "                sampled_y_train = sampled_train['Class']\n",
    "\n",
    "                if clf == 'cat_clf':\n",
    "                    new_model = CatBoostClassifier(**param)\n",
    "                    new_model.fit(sampled_X_train, sampled_y_train)\n",
    "                    y_pred_proba = new_model.predict_proba(X_val)[:, 1]\n",
    "                else:\n",
    "                    model.set_params(**param)\n",
    "                    model.fit(sampled_X_train, sampled_y_train)\n",
    "                    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "                score = roc_auc_score(y_val, y_pred_proba)\n",
    "                scores.append(score)\n",
    "\n",
    "            avg_score = np.mean(scores)\n",
    "            temp = pd.DataFrame({'model': clf, 'parameter': [param], 'roc_auc': avg_score})\n",
    "            result = pd.concat([result, temp], ignore_index=True)\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier()\n",
    "lgbm_clf = LGBMClassifier()\n",
    "cat_clf = CatBoostClassifier(verbose=True)\n",
    "\n",
    "classifier = {'xgb_clf': xgb_clf,\n",
    "              'lgbm_clf': lgbm_clf,\n",
    "              'cat_clf': cat_clf}\n",
    "\n",
    "classifiers_parameters = {'xgb_clf': {'n_estimators': [200],\n",
    "                                     'max_depth': [3, 4, 5],\n",
    "                                     'learning_rate': [0.03, 0.04],\n",
    "                                     'objective': ['binary:logistic']},\n",
    "\n",
    "                         'cat_clf': {'n_estimators': [200],\n",
    "                                     'learning_rate': [0.03, 0.045], \n",
    "                                     'depth': [6, 8],\n",
    "                                     'min_data_in_leaf': [12, 14],\n",
    "                                     'boosting_type': ['Plain'],\n",
    "                                     'bootstrap_type': ['Bernoulli'],\n",
    "                                     'verbose': [False]},\n",
    "\n",
    "                         'lgbm_clf' : {'n_estimators': [200],\n",
    "                                       'learning_rate': [0.03, 0.04],\n",
    "                                       'max_depth': [4, 6],\n",
    "                                       'num_leaves': [50, 70]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>parameter</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cat_clf</td>\n",
       "      <td>{'boosting_type': 'Plain', 'bootstrap_type': '...</td>\n",
       "      <td>0.897945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cat_clf</td>\n",
       "      <td>{'boosting_type': 'Plain', 'bootstrap_type': '...</td>\n",
       "      <td>0.897945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cat_clf</td>\n",
       "      <td>{'boosting_type': 'Plain', 'bootstrap_type': '...</td>\n",
       "      <td>0.895474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cat_clf</td>\n",
       "      <td>{'boosting_type': 'Plain', 'bootstrap_type': '...</td>\n",
       "      <td>0.895474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cat_clf</td>\n",
       "      <td>{'boosting_type': 'Plain', 'bootstrap_type': '...</td>\n",
       "      <td>0.893638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cat_clf</td>\n",
       "      <td>{'boosting_type': 'Plain', 'bootstrap_type': '...</td>\n",
       "      <td>0.893638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cat_clf</td>\n",
       "      <td>{'boosting_type': 'Plain', 'bootstrap_type': '...</td>\n",
       "      <td>0.893617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cat_clf</td>\n",
       "      <td>{'boosting_type': 'Plain', 'bootstrap_type': '...</td>\n",
       "      <td>0.893617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgb_clf</td>\n",
       "      <td>{'learning_rate': 0.04, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.891253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>lgbm_clf</td>\n",
       "      <td>{'learning_rate': 0.04, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.890479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lgbm_clf</td>\n",
       "      <td>{'learning_rate': 0.04, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.890479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lgbm_clf</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.889130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lgbm_clf</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.889130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lgbm_clf</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.887771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xgb_clf</td>\n",
       "      <td>{'learning_rate': 0.04, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.887591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xgb_clf</td>\n",
       "      <td>{'learning_rate': 0.04, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.887498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lgbm_clf</td>\n",
       "      <td>{'learning_rate': 0.04, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.887473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lgbm_clf</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.886995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgb_clf</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.886178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lgbm_clf</td>\n",
       "      <td>{'learning_rate': 0.04, 'max_depth': 6, 'n_est...</td>\n",
       "      <td>0.885568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgb_clf</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.885201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgb_clf</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.884705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model                                          parameter   roc_auc\n",
       "11   cat_clf  {'boosting_type': 'Plain', 'bootstrap_type': '...  0.897945\n",
       "10   cat_clf  {'boosting_type': 'Plain', 'bootstrap_type': '...  0.897945\n",
       "6    cat_clf  {'boosting_type': 'Plain', 'bootstrap_type': '...  0.895474\n",
       "7    cat_clf  {'boosting_type': 'Plain', 'bootstrap_type': '...  0.895474\n",
       "8    cat_clf  {'boosting_type': 'Plain', 'bootstrap_type': '...  0.893638\n",
       "9    cat_clf  {'boosting_type': 'Plain', 'bootstrap_type': '...  0.893638\n",
       "12   cat_clf  {'boosting_type': 'Plain', 'bootstrap_type': '...  0.893617\n",
       "13   cat_clf  {'boosting_type': 'Plain', 'bootstrap_type': '...  0.893617\n",
       "3    xgb_clf  {'learning_rate': 0.04, 'max_depth': 3, 'n_est...  0.891253\n",
       "19  lgbm_clf  {'learning_rate': 0.04, 'max_depth': 4, 'n_est...  0.890479\n",
       "18  lgbm_clf  {'learning_rate': 0.04, 'max_depth': 4, 'n_est...  0.890479\n",
       "14  lgbm_clf  {'learning_rate': 0.03, 'max_depth': 4, 'n_est...  0.889130\n",
       "15  lgbm_clf  {'learning_rate': 0.03, 'max_depth': 4, 'n_est...  0.889130\n",
       "16  lgbm_clf  {'learning_rate': 0.03, 'max_depth': 6, 'n_est...  0.887771\n",
       "4    xgb_clf  {'learning_rate': 0.04, 'max_depth': 4, 'n_est...  0.887591\n",
       "5    xgb_clf  {'learning_rate': 0.04, 'max_depth': 5, 'n_est...  0.887498\n",
       "21  lgbm_clf  {'learning_rate': 0.04, 'max_depth': 6, 'n_est...  0.887473\n",
       "17  lgbm_clf  {'learning_rate': 0.03, 'max_depth': 6, 'n_est...  0.886995\n",
       "0    xgb_clf  {'learning_rate': 0.03, 'max_depth': 3, 'n_est...  0.886178\n",
       "20  lgbm_clf  {'learning_rate': 0.04, 'max_depth': 6, 'n_est...  0.885568\n",
       "2    xgb_clf  {'learning_rate': 0.03, 'max_depth': 5, 'n_est...  0.885201\n",
       "1    xgb_clf  {'learning_rate': 0.03, 'max_depth': 4, 'n_est...  0.884705"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3_result = hyper_parameter_search(scaled, classifier, classifiers_parameters).sort_values('roc_auc', ascending=False)\n",
    "model3_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boosting_type</th>\n",
       "      <th>bootstrap_type</th>\n",
       "      <th>depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>min_data_in_leaf</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>verbose</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>objective</th>\n",
       "      <th>num_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plain</td>\n",
       "      <td>Bernoulli</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>14.0</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plain</td>\n",
       "      <td>Bernoulli</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>12.0</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plain</td>\n",
       "      <td>Bernoulli</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>12.0</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Plain</td>\n",
       "      <td>Bernoulli</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>14.0</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plain</td>\n",
       "      <td>Bernoulli</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.045</td>\n",
       "      <td>12.0</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Plain</td>\n",
       "      <td>Bernoulli</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.045</td>\n",
       "      <td>14.0</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Plain</td>\n",
       "      <td>Bernoulli</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.045</td>\n",
       "      <td>12.0</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Plain</td>\n",
       "      <td>Bernoulli</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.045</td>\n",
       "      <td>14.0</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  boosting_type bootstrap_type  depth  learning_rate  min_data_in_leaf  \\\n",
       "0         Plain      Bernoulli    8.0          0.030              14.0   \n",
       "1         Plain      Bernoulli    8.0          0.030              12.0   \n",
       "2         Plain      Bernoulli    6.0          0.030              12.0   \n",
       "3         Plain      Bernoulli    6.0          0.030              14.0   \n",
       "4         Plain      Bernoulli    6.0          0.045              12.0   \n",
       "5         Plain      Bernoulli    6.0          0.045              14.0   \n",
       "6         Plain      Bernoulli    8.0          0.045              12.0   \n",
       "7         Plain      Bernoulli    8.0          0.045              14.0   \n",
       "8           NaN            NaN    NaN          0.040               NaN   \n",
       "9           NaN            NaN    NaN          0.040               NaN   \n",
       "\n",
       "   n_estimators verbose  max_depth        objective  num_leaves  \n",
       "0           200   False        NaN              NaN         NaN  \n",
       "1           200   False        NaN              NaN         NaN  \n",
       "2           200   False        NaN              NaN         NaN  \n",
       "3           200   False        NaN              NaN         NaN  \n",
       "4           200   False        NaN              NaN         NaN  \n",
       "5           200   False        NaN              NaN         NaN  \n",
       "6           200   False        NaN              NaN         NaN  \n",
       "7           200   False        NaN              NaN         NaN  \n",
       "8           200     NaN        3.0  binary:logistic         NaN  \n",
       "9           200     NaN        4.0              NaN        70.0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10 = pd.json_normalize(model3_result[:10]['parameter'])\n",
    "top10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoostClassifier와 XGBClassifier 기반 보팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC-AUC: 0.8964238383372811\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(n_estimators=200,\n",
    "                        max_depth=4,\n",
    "                        learning_rate=0.04,\n",
    "                        objective='binary:logistic')\n",
    "\n",
    "cat_clf = CatBoostClassifier(n_estimators=200,\n",
    "                             learning_rate=0.03,\n",
    "                             depth=8,\n",
    "                             min_data_in_leaf=14,\n",
    "                             boosting_type='Plain',\n",
    "                             bootstrap_type='Bernoulli',\n",
    "                             verbose=False)\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "scores = []\n",
    "X = scaled.drop(['Class'], axis=1)\n",
    "y = scaled['Class']\n",
    "\n",
    "for train_index, val_index in skf.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    sampled_train = undersampling(pd.concat([X_train, y_train], axis=1))\n",
    "    sampled_X_train = sampled_train.drop(['Class'], axis=1)\n",
    "    sampled_y_train = sampled_train['Class']\n",
    "    \n",
    "    vo_clf = VotingClassifier(estimators=[('XGB', xgb_clf), ('CAT', cat_clf)], voting='soft')\n",
    "    vo_clf.fit(sampled_X_train, sampled_y_train)\n",
    "    y_pred_proba = vo_clf.predict_proba(X_val)[:, 1]\n",
    "    score = roc_auc_score(y_val, y_pred_proba)\n",
    "    \n",
    "    scores.append(score)\n",
    "\n",
    "average_score = np.mean(scores)\n",
    "print(\"Average ROC-AUC: {}\".format(average_score))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종 모델인 CatBoostClassifier로 Test Data 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8928892763082932\n"
     ]
    }
   ],
   "source": [
    "cat_clf = CatBoostClassifier(n_estimators=200,\n",
    "                             learning_rate=0.03,\n",
    "                             depth=8,\n",
    "                             min_data_in_leaf=14,\n",
    "                             boosting_type='Plain',\n",
    "                             bootstrap_type='Bernoulli',\n",
    "                             verbose=False)\n",
    "train_data = undersampling(scaled)\n",
    "X_train = train_data.drop(['Class'], axis=1)\n",
    "y_train = train_data['Class']\n",
    "X_test = scaled_test.drop(['Class'], axis=1)\n",
    "y_test = scaled_test['Class']\n",
    "\n",
    "cat_clf.fit(X_train, y_train)\n",
    "y_pred_proba = cat_clf.predict_proba(X_test)[:,1]\n",
    "score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
